{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e78321",
   "metadata": {},
   "source": [
    "# Final Clean Hybrid MuReD Notebook v3\n",
    "\n",
    "DenseNet121 + ResNet101 hybrid, image size 192, FOV extraction, blur filtering (drop bottom 10%), pos_weight, WeightedRandomSampler, Albumentations, MixUp, gradual unfreeze, AMP, checkpointing & resume, threshold tuning, MC-Dropout uncertainty, Grad-CAM, failure gallery, full evaluation metrics (AUC/AP/F1) — ready to run on RTX 3060/3070/4090.\n",
    "\n",
    "**Paths** used:\n",
    "- Images: `/mnt/data/images/`\n",
    "- Train CSV: `/mnt/data/train_data.csv`\n",
    "- Test CSV: `/mnt/data/test_data.csv`\n",
    "\n",
    "Run cells top → bottom. Adjust paths if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767d2e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu IMG_DIR exists: True\n"
     ]
    }
   ],
   "source": [
    "# === Imports & Config ===\n",
    "import os, time, math, random, gc\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, f1_score, precision_score, recall_score\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Paths & settings\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = torch.device('cpu')\n",
    "IMG_DIR = './MuReD_dataset/images'\n",
    "TRAIN_CSV = './MuReD_dataset/train_data.csv'\n",
    "TEST_CSV = './MuReD_dataset/test_data.csv'\n",
    "CACHE_DIR = \"./cache/new\"\n",
    "CACHE_FILE = os.path.join(CACHE_DIR, \"blur_cache.pkl\")\n",
    "\n",
    "IMG_SIZE = 192\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# Training schedule for RTX GPUs\n",
    "WARMUP_EPOCHS = 5\n",
    "MAIN_EPOCHS = 30\n",
    "TOTAL_EPOCHS = WARMUP_EPOCHS + MAIN_EPOCHS\n",
    "\n",
    "CKPT_DIR = './MuReD_dataset/checkpoints/'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "OUT_DIR = './MuReD_dataset/output/'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print('Device:', DEVICE, 'IMG_DIR exists:', os.path.exists(IMG_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf824c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOV and blur helpers ready\n"
     ]
    }
   ],
   "source": [
    "# === FOV extraction and blur metric helpers ===\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def extract_fov(img_rgb, tol=7):\n",
    "    \"\"\"Crop image to field-of-view (non-black area). img_rgb: HxWx3 uint8.\"\"\"\n",
    "    if img_rgb is None:\n",
    "        return img_rgb\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    mask = gray > tol\n",
    "    if mask.sum() == 0:\n",
    "        return img_rgb\n",
    "    coords = np.argwhere(mask)\n",
    "    y0, x0 = coords.min(axis=0)\n",
    "    y1, x1 = coords.max(axis=0)\n",
    "    crop = img_rgb[y0:y1+1, x0:x1+1]\n",
    "    return crop\n",
    "\n",
    "def blur_score(img_rgb):\n",
    "    \"\"\"Laplacian variance as blur score.\"\"\"\n",
    "    if img_rgb is None:\n",
    "        return 0.0\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    return float(cv2.Laplacian(gray, cv2.CV_64F).var())\n",
    "\n",
    "print('FOV and blur helpers ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5fcad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1764, 21) Test shape: (444, 21)\n",
      "Detected label columns (20): ['DR', 'NORMAL', 'MH', 'ODC', 'TSLN', 'ARMD', 'DN', 'MYA', 'BRVO', 'ODP', 'CRVO', 'CNV', 'RS', 'ODE', 'LS', 'CSR', 'HTR', 'ASR', 'CRS', 'OTHER']\n",
      "✔ Loaded blur scores from cache: ./cache/new\\blur_cache.pkl\n",
      "After dropping bottom 10%: 1588\n",
      "Labels shape: (1588, 20)\n"
     ]
    }
   ],
   "source": [
    "# === Blur Score Cache System (Optimized) ===\n",
    "\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# Load train/test CSV\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "print('Train shape:', train_df.shape, 'Test shape:', test_df.shape)\n",
    "\n",
    "if 'ID' not in train_df.columns:\n",
    "    raise ValueError(\"train_data.csv must contain ID column\")\n",
    "\n",
    "label_cols = [c for c in train_df.columns if c != 'ID']\n",
    "print(f\"Detected label columns ({len(label_cols)}):\", label_cols)\n",
    "\n",
    "# === Load from cache if available ===\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    cached = pd.read_pickle(CACHE_FILE)\n",
    "    train_df['blur_score'] = cached['blur_score']\n",
    "    print(\"✔ Loaded blur scores from cache:\", CACHE_FILE)\n",
    "\n",
    "else:\n",
    "    print(\"✖ Cache missing — computing blur scores...\")\n",
    "\n",
    "    blur_scores = []\n",
    "    for idx, row in train_df.iterrows():\n",
    "        img_id = str(row['ID'])\n",
    "        p = None\n",
    "\n",
    "        # Try common extensions\n",
    "        for ext in ['.jpg','.jpeg','.png','.tif','.tiff']:\n",
    "            cand = os.path.join(IMG_DIR, img_id + ext)\n",
    "            if os.path.exists(cand):\n",
    "                p = cand\n",
    "                break\n",
    "\n",
    "        # Direct match\n",
    "        if p is None:\n",
    "            cand2 = os.path.join(IMG_DIR, img_id)\n",
    "            if os.path.exists(cand2):\n",
    "                p = cand2\n",
    "\n",
    "        # Fallback: any file starting with ID\n",
    "        if p is None:\n",
    "            matches = glob(os.path.join(IMG_DIR, img_id + '*'))\n",
    "            p = matches[0] if matches else None\n",
    "\n",
    "        if p is None:\n",
    "            blur_scores.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = np.array(Image.open(p).convert(\"RGB\"))\n",
    "            fov = extract_fov(img)\n",
    "            b = blur_score(fov)\n",
    "            blur_scores.append(b)\n",
    "        except:\n",
    "            blur_scores.append(np.nan)\n",
    "\n",
    "    train_df['blur_score'] = blur_scores\n",
    "\n",
    "    # Save to cache\n",
    "    train_df[['blur_score']].to_pickle(CACHE_FILE)\n",
    "    print(\"✔ Cached blur scores to:\", CACHE_FILE)\n",
    "\n",
    "# === Drop bottom 10% low sharpness ===\n",
    "n_drop = int(0.10 * len(train_df))\n",
    "train_df = train_df.sort_values('blur_score', na_position='first').iloc[n_drop:].reset_index(drop=True)\n",
    "print(\"After dropping bottom 10%:\", len(train_df))\n",
    "\n",
    "# Labels\n",
    "labels_all = train_df[label_cols].values.astype(np.float32)\n",
    "print(\"Labels shape:\", labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243480a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterative stratify not available, falling back to simple split: No module named 'iterstrat'\n",
      "Train/Val sizes: (1270, 22) (318, 22)\n"
     ]
    }
   ],
   "source": [
    "# === Train/Val split (iterative stratify if available) ===\n",
    "try:\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "    splitter = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "    train_idx, val_idx = next(splitter.split(train_df, labels_all))\n",
    "    print('Used MultilabelStratifiedShuffleSplit')\n",
    "except Exception as e:\n",
    "    print('iterative stratify not available, falling back to simple split:', e)\n",
    "    train_idx, val_idx = train_test_split(np.arange(len(train_df)), test_size=0.2, random_state=SEED)\n",
    "\n",
    "df_tr = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "df_val = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "y_train = df_tr[label_cols].values.astype(np.float32)\n",
    "y_val = df_val[label_cols].values.astype(np.float32)\n",
    "print('Train/Val sizes:', df_tr.shape, df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7548866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_weight (first 10): [ 3.6014493  3.4561403 14.119047   7.3006535 12.804348  12.368421\n",
      " 12.092784  34.27778   27.863636  33.324326 ]\n"
     ]
    }
   ],
   "source": [
    "# === Compute pos_weight for BCEWithLogitsLoss ===\n",
    "pos = y_train.sum(axis=0).astype(np.float32)\n",
    "neg = y_train.shape[0] - pos\n",
    "pos_weight = np.clip((neg / (pos + 1e-6)).astype(np.float32), 1.0, 50.0)\n",
    "pos_weight_tensor = torch.tensor(pos_weight).to(DEVICE)\n",
    "num_classes = y_train.shape[1]\n",
    "print('pos_weight (first 10):', pos_weight[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb5a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforms set (IMG_SIZE=192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anves\\AppData\\Local\\Temp\\ipykernel_16012\\33596865.py:13: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=8, max_height=16, max_width=16),\n",
      "C:\\Users\\anves\\AppData\\Local\\Temp\\ipykernel_16012\\33596865.py:14: UserWarning: Argument(s) 'max_holes, min_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=8, min_holes=8, max_height=16, max_width=16),\n"
     ]
    }
   ],
   "source": [
    "# === Augmentations (Albumentations) ===\n",
    "train_tfms = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "\n",
    "    A.RandomResizedCrop(size=(IMG_SIZE, IMG_SIZE), scale=(0.8, 1.0), p=0.6),\n",
    "\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=20, p=0.3),\n",
    "    A.CLAHE(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(max_holes=8, max_height=16, max_width=16),\n",
    "        A.CoarseDropout(max_holes=8, min_holes=8, max_height=16, max_width=16),\n",
    "    ], p=0.3),\n",
    "\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_tfms = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "print(f'Transforms set (IMG_SIZE={IMG_SIZE})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d972983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MuReD Dataset class ===\n",
    "class MuReDDataset(Dataset):\n",
    "    def __init__(self, df, label_cols, transform, img_dir=IMG_DIR):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_cols = label_cols\n",
    "        self.transform = transform\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def _find_image(self, img_id):\n",
    "        for ext in ['.jpg','.jpeg','.png','.tif','.tiff']:\n",
    "            p = os.path.join(self.img_dir, str(img_id) + ext)\n",
    "            if os.path.exists(p):\n",
    "                return p\n",
    "        p2 = os.path.join(self.img_dir, str(img_id))\n",
    "        if os.path.exists(p2):\n",
    "            return p2\n",
    "        matches = glob(os.path.join(self.img_dir, str(img_id) + '*'))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "        return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row['ID']\n",
    "        p = self._find_image(img_id)\n",
    "        if p is None:\n",
    "            img_np = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            img_np = np.array(img)\n",
    "            # apply FOV extraction if available\n",
    "            try:\n",
    "                img_np = extract_fov(img_np)\n",
    "            except Exception:\n",
    "                pass\n",
    "        augmented = self.transform(image=img_np)\n",
    "        img_t = augmented['image']\n",
    "        labels = torch.tensor(row[self.label_cols].values.astype(np.float32))\n",
    "        return img_t, labels, str(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f1e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders ready. Train batches: 40 Val batches: 10\n"
     ]
    }
   ],
   "source": [
    "# === DataLoaders & WeightedRandomSampler ===\n",
    "label_freq = y_train.sum(axis=0) + 1e-6\n",
    "sample_weights = []\n",
    "for lbl in y_train:\n",
    "    present = lbl.astype(bool)\n",
    "    if present.sum() == 0:\n",
    "        w = 1.0\n",
    "    else:\n",
    "        w = (1.0 / label_freq[present]).sum()\n",
    "    sample_weights.append(w)\n",
    "\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_ds = MuReDDataset(df_tr, label_cols, train_tfms, img_dir=IMG_DIR)\n",
    "val_ds = MuReDDataset(df_val, label_cols, val_tfms, img_dir=IMG_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print('DataLoaders ready. Train batches:', len(train_loader), 'Val batches:', len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5da63c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, parameters: 52621268\n"
     ]
    }
   ],
   "source": [
    "# === Hybrid model: DenseNet121 + ResNet101 (concatenation fusion) ===\n",
    "class HybridNet(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.3, pretrained=True):\n",
    "        super().__init__()\n",
    "        densenet = models.densenet121(pretrained=pretrained)\n",
    "        self.dense_features = densenet.features  # out channels 1024\n",
    "        resnet = models.resnet101(pretrained=pretrained)\n",
    "        self.resnet_backbone = nn.Sequential(*list(resnet.children())[:-2])  # out channels 2048\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        fused_size = 1024 + 2048\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fused_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d = self.dense_features(x)  # B x 1024 x H x W\n",
    "        d = self.pool(d).view(d.size(0), -1)\n",
    "        r = self.resnet_backbone(x)  # B x 2048 x H' x W'\n",
    "        r = self.pool(r).view(r.size(0), -1)\n",
    "        fused = torch.cat([d, r], dim=1)\n",
    "        out = self.classifier(fused)\n",
    "        return out\n",
    "\n",
    "model = HybridNet(num_classes=num_classes, pretrained=True).to(DEVICE)\n",
    "print('Model created, parameters:', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc6a3915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion, optimizer, AMP scaler ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anves\\AppData\\Local\\Temp\\ipykernel_16012\\1991175779.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# === Loss, optimizer (head-only warmup), scheduler placeholders ===\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "# Freeze all except classifier\n",
    "for name, p in model.named_parameters():\n",
    "    if 'classifier' in name:\n",
    "        p.requires_grad = True\n",
    "    else:\n",
    "        p.requires_grad = False\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-4)\n",
    "# scaler for AMP\n",
    "scaler = GradScaler()\n",
    "print('Criterion, optimizer, AMP scaler ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5ca997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/eval functions ready\n"
     ]
    }
   ],
   "source": [
    "# === MixUp and training/evaluation functions ===\n",
    "import numpy as np\n",
    "\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    if alpha <= 0:\n",
    "        return x, y, 1.0\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0)).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[idx]\n",
    "    mixed_y = lam * y + (1 - lam) * y[idx]\n",
    "    return mixed_x, mixed_y, lam\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, scaler, mixup_alpha=0.4):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    print(\"→ train_one_epoch: starting epoch, waiting for first batch...\")\n",
    "\n",
    "    for batch_idx, (imgs, labels, _) in enumerate(loader):\n",
    "\n",
    "        # DEBUG: dataloader health\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"  Batch {batch_idx}/{len(loader)} loaded\")\n",
    "\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        imgs, labels, _ = mixup_data(imgs, labels, alpha=mixup_alpha)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "        print(f\"    Forward OK (batch {batch_idx})\")\n",
    "\n",
    "        # Backward + step\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        print(f\"    Backward+Step OK (batch {batch_idx})\")\n",
    "\n",
    "        running_loss += float(loss.item()) * imgs.size(0)\n",
    "        n += imgs.size(0)\n",
    "\n",
    "    return running_loss / (n + 1e-12)\n",
    "\n",
    "def predict_loader(model, loader):\n",
    "    model.eval()\n",
    "    preds = []; targs = []; names = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, img_ids in loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            out = torch.sigmoid(model(imgs))\n",
    "            preds.append(out.cpu().numpy())\n",
    "            targs.append(labels.numpy())\n",
    "            names += img_ids\n",
    "    if len(preds)==0:\n",
    "        return np.zeros((0, num_classes)), np.zeros((0, num_classes)), []\n",
    "    return np.vstack(preds), np.vstack(targs), names\n",
    "\n",
    "print('Training/eval functions ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52cbb0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Checkpoint save/load utilities ===\n",
    "def save_checkpoint(state, filename='checkpoint.pth'):\n",
    "    path = os.path.join(CKPT_DIR, filename)\n",
    "    torch.save(state, path)\n",
    "    print('Saved checkpoint:', path)\n",
    "\n",
    "def load_checkpoint(model, optimizer=None, scaler=None, filename='checkpoint.pth'):\n",
    "    path = os.path.join(CKPT_DIR, filename)\n",
    "    if not os.path.exists(path):\n",
    "        print(f'No checkpoint found at {path}')\n",
    "        return None\n",
    "\n",
    "    ck = torch.load(path, map_location=DEVICE)\n",
    "    model.load_state_dict(ck['model_state_dict'])\n",
    "    \n",
    "    # ========== Safe Optimizer Load ==========\n",
    "    if optimizer is not None and 'optimizer_state_dict' in ck:\n",
    "        try:\n",
    "            optimizer.load_state_dict(ck['optimizer_state_dict'])\n",
    "            print(\"✓ Optimizer state loaded successfully\")\n",
    "        except ValueError as e:\n",
    "            print(\"⚠️ Optimizer state NOT loaded (param group mismatch). Skipping.\")\n",
    "            print(\"Reason:\", str(e))\n",
    "            print(\"→ Continuing with fresh optimizer.\")\n",
    "    \n",
    "    # ========== Safe Scaler Load ==========\n",
    "    if scaler is not None and 'scaler_state_dict' in ck:\n",
    "        try:\n",
    "            scaler.load_state_dict(ck['scaler_state_dict'])\n",
    "            print(\"✓ Scaler loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(\"⚠️ Scaler NOT loaded. Skipping.\")\n",
    "            print(\"Reason:\", str(e))\n",
    "\n",
    "    print('Loaded checkpoint | epoch:', ck.get('epoch', '?'),\n",
    "          '| best_map:', ck.get('best_map', '?'))\n",
    "\n",
    "    return ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e11bef1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer reset with discriminative LR\n"
     ]
    }
   ],
   "source": [
    "# === Gradual unfreeze: unfreeze denseblock4 & resnet layer4 ===\n",
    "# Unfreeze classifier + last blocks\n",
    "for name, p in model.named_parameters():\n",
    "    if 'classifier' in name:\n",
    "        p.requires_grad = True\n",
    "    if 'denseblock4' in name or 'transition3' in name:\n",
    "        p.requires_grad = True\n",
    "    if 'resnet_backbone.7' in name or 'resnet_backbone.6' in name or 'resnet_backbone.8' in name or 'resnet_backbone.5' in name:\n",
    "        p.requires_grad = True\n",
    "\n",
    "backbone_params = [p for n,p in model.named_parameters() if p.requires_grad and ('classifier' not in n)]\n",
    "head_params     = [p for n,p in model.named_parameters() if p.requires_grad and ('classifier' in n)]\n",
    "\n",
    "param_groups = [\n",
    "    {'params': backbone_params, 'lr': 1e-5},\n",
    "    {'params': head_params,     'lr': 1e-4},\n",
    "]\n",
    "\n",
    "optimizer = optim.AdamW(param_groups, weight_decay=1e-4)\n",
    "print(\"Optimizer reset with discriminative LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67f651de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scaler loaded successfully\n",
      "Loaded checkpoint | epoch: 5 | best_map: 0.0\n",
      "Resuming from checkpoint, start_epoch: 5\n"
     ]
    }
   ],
   "source": [
    "# === Warmup: head-only training ===\n",
    "start_epoch = 0\n",
    "best_map = 0.0\n",
    "\n",
    "# Load ONLY model + scaler, NOT optimizer\n",
    "ck = load_checkpoint(model, optimizer=None, scaler=scaler, filename='main_checkpoint.pth')\n",
    "\n",
    "if ck is not None:\n",
    "    start_epoch = ck.get('epoch', 0)\n",
    "    best_map = ck.get('best_map', 0.0)\n",
    "    print('Resuming from checkpoint, start_epoch:', start_epoch)\n",
    "\n",
    "# Warmup epochs (train only classifier)\n",
    "for e in range(start_epoch, WARMUP_EPOCHS):\n",
    "    t0 = time.time()\n",
    "    print(f\"→ Starting Warmup Epoch {e+1}/{WARMUP_EPOCHS}\")\n",
    "    loss = train_one_epoch(model, train_loader, optimizer, criterion, scaler, mixup_alpha=0.0)\n",
    "    dt = time.time() - t0\n",
    "    print(f'Warmup Epoch {e+1}/{WARMUP_EPOCHS} - loss: {loss:.4f} - time: {dt:.1f}s')\n",
    "    # save checkpoint\n",
    "    save_checkpoint({\n",
    "        'epoch': e+1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'best_map': best_map\n",
    "    }, filename='main_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "239e1686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 6/35 - train_loss: 1.1365 - val_macro_auc: 0.8707 - val_macro_ap: 0.3899 - time: 666.6s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.3898522678441885\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 7/35 - train_loss: 1.0523 - val_macro_auc: 0.8735 - val_macro_ap: 0.3815 - time: 725.8s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 8/35 - train_loss: 1.0036 - val_macro_auc: 0.8771 - val_macro_ap: 0.3913 - time: 686.1s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.3913169881918807\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 9/35 - train_loss: 0.9890 - val_macro_auc: 0.8805 - val_macro_ap: 0.4155 - time: 619.7s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.41552596832942257\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 10/35 - train_loss: 0.9429 - val_macro_auc: 0.8821 - val_macro_ap: 0.4193 - time: 612.3s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.4193321618433756\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 11/35 - train_loss: 1.0713 - val_macro_auc: 0.8812 - val_macro_ap: 0.4118 - time: 615.2s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 12/35 - train_loss: 1.0350 - val_macro_auc: 0.8824 - val_macro_ap: 0.4211 - time: 614.9s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.42105938060491893\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 13/35 - train_loss: 0.9485 - val_macro_auc: 0.8815 - val_macro_ap: 0.4433 - time: 611.4s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.4432787504902276\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 14/35 - train_loss: 0.9852 - val_macro_auc: 0.8831 - val_macro_ap: 0.4513 - time: 618.1s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.4512922872155832\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 15/35 - train_loss: 0.9442 - val_macro_auc: 0.8857 - val_macro_ap: 0.4505 - time: 622.1s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 16/35 - train_loss: 0.9300 - val_macro_auc: 0.8883 - val_macro_ap: 0.4633 - time: 613.3s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.46334179367183354\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 17/35 - train_loss: 0.9695 - val_macro_auc: 0.8885 - val_macro_ap: 0.4523 - time: 612.4s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 18/35 - train_loss: 0.8846 - val_macro_auc: 0.8941 - val_macro_ap: 0.4624 - time: 618.5s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 19/35 - train_loss: 0.9423 - val_macro_auc: 0.8930 - val_macro_ap: 0.4509 - time: 607.8s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 20/35 - train_loss: 0.9442 - val_macro_auc: 0.8897 - val_macro_ap: 0.4697 - time: 615.4s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.4696780941859743\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 21/35 - train_loss: 0.9022 - val_macro_auc: 0.8912 - val_macro_ap: 0.4704 - time: 619.7s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.4703577546935608\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 22/35 - train_loss: 0.9362 - val_macro_auc: 0.8922 - val_macro_ap: 0.4693 - time: 620.7s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 23/35 - train_loss: 0.8547 - val_macro_auc: 0.8940 - val_macro_ap: 0.4871 - time: 619.9s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.4870765659645344\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 24/35 - train_loss: 0.8412 - val_macro_auc: 0.8901 - val_macro_ap: 0.4858 - time: 619.5s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 25/35 - train_loss: 0.9001 - val_macro_auc: 0.8900 - val_macro_ap: 0.4888 - time: 620.4s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.48877319483535475\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 26/35 - train_loss: 0.9147 - val_macro_auc: 0.8904 - val_macro_ap: 0.4706 - time: 613.1s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 27/35 - train_loss: 0.8671 - val_macro_auc: 0.8926 - val_macro_ap: 0.4696 - time: 623.0s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 28/35 - train_loss: 0.8530 - val_macro_auc: 0.8970 - val_macro_ap: 0.4814 - time: 622.0s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 29/35 - train_loss: 0.8653 - val_macro_auc: 0.8956 - val_macro_ap: 0.4793 - time: 621.9s\n",
      "LR reduced: [1e-05, 0.0001] → [5e-06, 5e-05]\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 30/35 - train_loss: 0.7760 - val_macro_auc: 0.8963 - val_macro_ap: 0.4856 - time: 619.7s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 31/35 - train_loss: 0.8529 - val_macro_auc: 0.8970 - val_macro_ap: 0.4850 - time: 621.4s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 32/35 - train_loss: 0.7986 - val_macro_auc: 0.9001 - val_macro_ap: 0.4905 - time: 619.1s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.4904564817084601\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 33/35 - train_loss: 0.8391 - val_macro_auc: 0.8995 - val_macro_ap: 0.4941 - time: 612.6s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/best_model.pth\n",
      "New best model saved with mAP: 0.4940699471625411\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 34/35 - train_loss: 0.7817 - val_macro_auc: 0.8979 - val_macro_ap: 0.4823 - time: 619.3s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n",
      "→ train_one_epoch: starting epoch, waiting for first batch...\n",
      "  Batch 0/40 loaded\n",
      "    Forward OK (batch 0)\n",
      "    Backward+Step OK (batch 0)\n",
      "    Forward OK (batch 1)\n",
      "    Backward+Step OK (batch 1)\n",
      "    Forward OK (batch 2)\n",
      "    Backward+Step OK (batch 2)\n",
      "    Forward OK (batch 3)\n",
      "    Backward+Step OK (batch 3)\n",
      "    Forward OK (batch 4)\n",
      "    Backward+Step OK (batch 4)\n",
      "    Forward OK (batch 5)\n",
      "    Backward+Step OK (batch 5)\n",
      "    Forward OK (batch 6)\n",
      "    Backward+Step OK (batch 6)\n",
      "    Forward OK (batch 7)\n",
      "    Backward+Step OK (batch 7)\n",
      "    Forward OK (batch 8)\n",
      "    Backward+Step OK (batch 8)\n",
      "    Forward OK (batch 9)\n",
      "    Backward+Step OK (batch 9)\n",
      "  Batch 10/40 loaded\n",
      "    Forward OK (batch 10)\n",
      "    Backward+Step OK (batch 10)\n",
      "    Forward OK (batch 11)\n",
      "    Backward+Step OK (batch 11)\n",
      "    Forward OK (batch 12)\n",
      "    Backward+Step OK (batch 12)\n",
      "    Forward OK (batch 13)\n",
      "    Backward+Step OK (batch 13)\n",
      "    Forward OK (batch 14)\n",
      "    Backward+Step OK (batch 14)\n",
      "    Forward OK (batch 15)\n",
      "    Backward+Step OK (batch 15)\n",
      "    Forward OK (batch 16)\n",
      "    Backward+Step OK (batch 16)\n",
      "    Forward OK (batch 17)\n",
      "    Backward+Step OK (batch 17)\n",
      "    Forward OK (batch 18)\n",
      "    Backward+Step OK (batch 18)\n",
      "    Forward OK (batch 19)\n",
      "    Backward+Step OK (batch 19)\n",
      "  Batch 20/40 loaded\n",
      "    Forward OK (batch 20)\n",
      "    Backward+Step OK (batch 20)\n",
      "    Forward OK (batch 21)\n",
      "    Backward+Step OK (batch 21)\n",
      "    Forward OK (batch 22)\n",
      "    Backward+Step OK (batch 22)\n",
      "    Forward OK (batch 23)\n",
      "    Backward+Step OK (batch 23)\n",
      "    Forward OK (batch 24)\n",
      "    Backward+Step OK (batch 24)\n",
      "    Forward OK (batch 25)\n",
      "    Backward+Step OK (batch 25)\n",
      "    Forward OK (batch 26)\n",
      "    Backward+Step OK (batch 26)\n",
      "    Forward OK (batch 27)\n",
      "    Backward+Step OK (batch 27)\n",
      "    Forward OK (batch 28)\n",
      "    Backward+Step OK (batch 28)\n",
      "    Forward OK (batch 29)\n",
      "    Backward+Step OK (batch 29)\n",
      "  Batch 30/40 loaded\n",
      "    Forward OK (batch 30)\n",
      "    Backward+Step OK (batch 30)\n",
      "    Forward OK (batch 31)\n",
      "    Backward+Step OK (batch 31)\n",
      "    Forward OK (batch 32)\n",
      "    Backward+Step OK (batch 32)\n",
      "    Forward OK (batch 33)\n",
      "    Backward+Step OK (batch 33)\n",
      "    Forward OK (batch 34)\n",
      "    Backward+Step OK (batch 34)\n",
      "    Forward OK (batch 35)\n",
      "    Backward+Step OK (batch 35)\n",
      "    Forward OK (batch 36)\n",
      "    Backward+Step OK (batch 36)\n",
      "    Forward OK (batch 37)\n",
      "    Backward+Step OK (batch 37)\n",
      "    Forward OK (batch 38)\n",
      "    Backward+Step OK (batch 38)\n",
      "    Forward OK (batch 39)\n",
      "    Backward+Step OK (batch 39)\n",
      "Epoch 35/35 - train_loss: 0.7328 - val_macro_auc: 0.9002 - val_macro_ap: 0.4857 - time: 619.5s\n",
      "Saved checkpoint: ./MuReD_dataset/checkpoints/main_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "# === Full training (main) ===\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "E_start = WARMUP_EPOCHS\n",
    "best_map = best_map if 'best_map' in globals() else 0.0\n",
    "\n",
    "# Optionally use scheduler; here we use ReduceLROnPlateau on val mAP\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "for epoch in range(E_start, E_start + MAIN_EPOCHS):\n",
    "    t0 = time.time()\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, scaler, mixup_alpha=0.4)\n",
    "    preds, targs, names = predict_loader(model, val_loader)\n",
    "    if preds.shape[0] > 0:\n",
    "        try:\n",
    "            macro_auc = roc_auc_score(targs, preds, average='macro')\n",
    "        except Exception:\n",
    "            macro_auc = float('nan')\n",
    "        macro_ap = average_precision_score(targs, preds, average='macro')\n",
    "    else:\n",
    "        macro_auc = macro_ap = 0.0\n",
    "    dt = time.time() - t0\n",
    "    print(f'Epoch {epoch+1}/{E_start+MAIN_EPOCHS} - train_loss: {train_loss:.4f} - val_macro_auc: {macro_auc:.4f} - val_macro_ap: {macro_ap:.4f} - time: {dt:.1f}s')\n",
    "\n",
    "    old_lrs = [g['lr'] for g in optimizer.param_groups]\n",
    "    # scheduler step\n",
    "    scheduler.step(macro_ap)\n",
    "    new_lrs = [g['lr'] for g in optimizer.param_groups]\n",
    "\n",
    "    if new_lrs != old_lrs:\n",
    "        print(f\"LR reduced: {old_lrs} → {new_lrs}\")\n",
    "\n",
    "    # save checkpoint (main) and best\n",
    "    ck_state = {\n",
    "        'epoch': epoch+1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'best_map': best_map\n",
    "    }\n",
    "    save_checkpoint(ck_state, filename='main_checkpoint.pth')\n",
    "\n",
    "    if macro_ap > best_map:\n",
    "        best_map = macro_ap\n",
    "        save_checkpoint(ck_state, filename='best_model.pth')\n",
    "        print('New best model saved with mAP:', best_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c036e22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best thresholds (first 10): [0.45183086 0.37426716 0.81934994 0.83328742 0.89129949 0.84718233\n",
      " 0.56688976 0.80646276 0.91708744 0.89069253]\n",
      "DR: F1=0.667, Prec=0.603, Rec=0.746\n",
      "NORMAL: F1=0.722, Prec=0.602, Rec=0.903\n",
      "MH: F1=0.659, Prec=0.540, Rec=0.844\n",
      "ODC: F1=0.519, Prec=0.538, Rec=0.500\n",
      "TSLN: F1=0.500, Prec=0.450, Rec=0.562\n",
      "ARMD: F1=0.605, Prec=0.591, Rec=0.619\n",
      "DN: F1=0.263, Prec=0.175, Rec=0.526\n",
      "MYA: F1=0.864, Prec=0.864, Rec=0.864\n",
      "BRVO: F1=0.455, Prec=1.000, Rec=0.294\n",
      "ODP: F1=0.400, Prec=0.286, Rec=0.667\n",
      "CRVO: F1=0.857, Prec=0.750, Rec=1.000\n",
      "CNV: F1=0.750, Prec=0.818, Rec=0.692\n",
      "RS: F1=0.500, Prec=0.400, Rec=0.667\n",
      "ODE: F1=0.778, Prec=0.875, Rec=0.700\n",
      "LS: F1=0.421, Prec=0.400, Rec=0.444\n",
      "CSR: F1=0.385, Prec=0.250, Rec=0.833\n",
      "HTR: F1=0.267, Prec=0.200, Rec=0.400\n",
      "ASR: F1=0.133, Prec=0.091, Rec=0.250\n",
      "CRS: F1=0.857, Prec=1.000, Rec=0.750\n",
      "OTHER: F1=0.312, Prec=0.222, Rec=0.526\n",
      "\n",
      "Macro AUC: 0.9002446269088908\n",
      "Macro AP: 0.4857430544110577\n"
     ]
    }
   ],
   "source": [
    "# === Threshold tuning (per-class) and detailed metrics ===\n",
    "preds, targs, names = predict_loader(model, val_loader)\n",
    "best_thr = np.zeros(num_classes)\n",
    "for i in range(num_classes):\n",
    "    try:\n",
    "        p, r, th = precision_recall_curve(targs[:,i], preds[:,i])\n",
    "        f1 = 2*p*r/(p+r+1e-8)\n",
    "        if len(f1) > 1:\n",
    "            best_thr[i] = th[np.argmax(f1[:-1])]\n",
    "        else:\n",
    "            best_thr[i] = 0.5\n",
    "    except Exception:\n",
    "        best_thr[i] = 0.5\n",
    "print('Best thresholds (first 10):', best_thr[:10])\n",
    "\n",
    "# Binarize using thresholds and compute metrics\n",
    "bin_preds = (preds >= best_thr.reshape(1,-1)).astype(int)\n",
    "per_class_f1 = [f1_score(targs[:,i], bin_preds[:,i]) for i in range(num_classes)]\n",
    "per_class_precision = [precision_score(targs[:,i], bin_preds[:,i], zero_division=0) for i in range(num_classes)]\n",
    "per_class_recall = [recall_score(targs[:,i], bin_preds[:,i], zero_division=0) for i in range(num_classes)]\n",
    "\n",
    "for c, f, p, r in zip(label_cols, per_class_f1, per_class_precision, per_class_recall):\n",
    "    print(f\"{c}: F1={f:.3f}, Prec={p:.3f}, Rec={r:.3f}\")\n",
    "\n",
    "print('\\nMacro AUC:', roc_auc_score(targs, preds, average='macro'))\n",
    "print('Macro AP:', average_precision_score(targs, preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4b7fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prediction report to ./MuReD_dataset/output/val_prediction_report_with_uncertainty.csv\n"
     ]
    }
   ],
   "source": [
    "# === MC-Dropout uncertainty estimation & save report ===\n",
    "def enable_dropout(m):\n",
    "    for mod in m.modules():\n",
    "        if isinstance(mod, nn.Dropout):\n",
    "            mod.train()\n",
    "\n",
    "T = 12\n",
    "enable_dropout(model)\n",
    "all_preds = []\n",
    "for t in range(T):\n",
    "    p, _, _ = predict_loader(model, val_loader)\n",
    "    all_preds.append(p)\n",
    "all_preds = np.stack(all_preds)  # T x n x C\n",
    "pred_mean = all_preds.mean(axis=0)\n",
    "pred_std = all_preds.std(axis=0)\n",
    "\n",
    "probs = pred_mean\n",
    "bin_preds = (probs >= best_thr.reshape(1,-1)).astype(int)\n",
    "\n",
    "rows = []\n",
    "for i, img_name in enumerate(names):\n",
    "    rows.append({\n",
    "        'image': img_name,\n",
    "        'true': ','.join([str(int(x)) for x in targs[i]]),\n",
    "        'pred_top3': ';'.join([f\"{label_cols[j]}:{probs[i,j]:.3f}\" for j in np.argsort(-probs[i])[:3]]),\n",
    "        'uncertainty_mean': float(pred_std[i].mean()),\n",
    "        'probs_json': json.dumps({label_cols[j]: float(probs[i,j]) for j in range(num_classes)}),\n",
    "        'bin_pred': ','.join([label_cols[j] for j in np.where(bin_preds[i]==1)[0]])\n",
    "    })\n",
    "\n",
    "df_report = pd.DataFrame(rows)\n",
    "report_path = os.path.join(OUT_DIR, 'val_prediction_report_with_uncertainty.csv')\n",
    "df_report.to_csv(report_path, index=False)\n",
    "print('Saved prediction report to', report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af8dd7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad-cam not installed. pip install grad-cam to enable visualization: No module named 'pytorch_grad_cam'\n",
      "Dense target: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) ResNet target module: None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m val_iter = \u001b[38;5;28miter\u001b[39m(val_loader)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[32m12\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_loader))):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     imgs, labels_batch, id_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     img_tensor = imgs[\u001b[32m0\u001b[39m].to(DEVICE)\n\u001b[32m     26\u001b[39m     name = id_batch[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mMuReDDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# apply FOV extraction if available\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     img_np = \u001b[43mextract_fov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mextract_fov\u001b[39m\u001b[34m(img_rgb, tol)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.sum() == \u001b[32m0\u001b[39m:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img_rgb\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m coords = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m y0, x0 = coords.min(axis=\u001b[32m0\u001b[39m)\n\u001b[32m     15\u001b[39m y1, x1 = coords.max(axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\numpy\\_core\\numeric.py:639\u001b[39m, in \u001b[36margwhere\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m    637\u001b[39m     \u001b[38;5;66;03m# then remove the added dimension\u001b[39;00m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m argwhere(a)[:, :\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:703\u001b[39m, in \u001b[36mtranspose\u001b[39m\u001b[34m(a, axes)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_transpose_dispatcher)\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtranspose\u001b[39m(a, axes=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    632\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[33;03m    Returns an array with axes transposed.\u001b[39;00m\n\u001b[32m    634\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    701\u001b[39m \n\u001b[32m    702\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtranspose\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:54\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     52\u001b[39m bound = \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(*args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anves\\OneDrive\\Desktop\\Siddhi Jaiswal Model\\venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:42\u001b[39m, in \u001b[36m_wrapit\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapit\u001b[39m(obj, method, *args, **kwds):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     conv = \u001b[43m_array_converter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# As this already tried the method, subok is maybe quite reasonable here\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# but this follows what was done before. TODO: revisit this.\u001b[39;00m\n\u001b[32m     45\u001b[39m     arr, = conv.as_arrays(subok=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === Grad-CAM for Hybrid Model (combine DenseNet & ResNet cams) ===\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "except Exception as e:\n",
    "    print('grad-cam not installed. pip install grad-cam to enable visualization:', e)\n",
    "\n",
    "# find target layers\n",
    "dense_target = None\n",
    "resnet_target = None\n",
    "for n, m in model.named_modules():\n",
    "    if 'denseblock4' in n and isinstance(m, nn.Conv2d):\n",
    "        dense_target = m\n",
    "    if 'resnet_backbone' in n and 'layer4' in n:\n",
    "        resnet_target = m\n",
    "\n",
    "print('Dense target:', dense_target, 'ResNet target module:', resnet_target)\n",
    "\n",
    "OUT_CAM_DIR = os.path.join(OUT_DIR, 'gradcam_overlays'); os.makedirs(OUT_CAM_DIR, exist_ok=True)\n",
    "\n",
    "val_iter = iter(val_loader)\n",
    "for idx in range(min(12, len(val_loader))):\n",
    "    imgs, labels_batch, id_batch = next(val_iter)\n",
    "    img_tensor = imgs[0].to(DEVICE)\n",
    "    name = id_batch[0]\n",
    "    probs_img = torch.sigmoid(model(img_tensor.unsqueeze(0))).detach().cpu().numpy()[0]\n",
    "    topk = np.argsort(-probs_img)[:3]\n",
    "    for cls_idx in topk:\n",
    "        try:\n",
    "            cam_d = GradCAM(model=model, target_layers=[dense_target], use_cuda=torch.cuda.is_available())\n",
    "            cam_r = GradCAM(model=model, target_layers=[resnet_target], use_cuda=torch.cuda.is_available())\n",
    "            gcam_d = cam_d(input_tensor=img_tensor.unsqueeze(0), targets=[ClassifierOutputTarget(int(cls_idx))])[0]\n",
    "            gcam_r = cam_r(input_tensor=img_tensor.unsqueeze(0), targets=[ClassifierOutputTarget(int(cls_idx))])[0]\n",
    "            cam_avg = (gcam_d + gcam_r) / 2.0\n",
    "            model_img_path = None\n",
    "            for ext in ['.jpg','.jpeg','.png','.tif','.tiff','']:\n",
    "                cand = os.path.join(IMG_DIR, name + ext)\n",
    "                if os.path.exists(cand):\n",
    "                    model_img_path = cand; break\n",
    "            if model_img_path is None:\n",
    "                matches = glob(os.path.join(IMG_DIR, name + '*'))\n",
    "                if len(matches)>0:\n",
    "                    model_img_path = matches[0]\n",
    "            if model_img_path is None:\n",
    "                continue\n",
    "            orig = np.array(Image.open(model_img_path).convert('RGB').resize((IMG_SIZE, IMG_SIZE)))/255.0\n",
    "            viz = show_cam_on_image(orig, cam_avg, use_rgb=True)\n",
    "            outp = os.path.join(OUT_CAM_DIR, f\"{name}_cls{cls_idx}.jpg\")\n",
    "            import cv2\n",
    "            cv2.imwrite(outp, viz)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "print('Saved Grad-CAM overlays to', OUT_CAM_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4be20c38",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# === Failure-case gallery (save False Negatives) ===\u001b[39;00m\n\u001b[32m      2\u001b[39m FAIL_DIR = os.path.join(OUT_DIR, \u001b[33m'\u001b[39m\u001b[33mfailure_gallery\u001b[39m\u001b[33m'\u001b[39m); os.makedirs(FAIL_DIR, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m bin_preds = (\u001b[43mprobs\u001b[49m >= best_thr.reshape(\u001b[32m1\u001b[39m,-\u001b[32m1\u001b[39m)).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cls_idx, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(label_cols):\n\u001b[32m      5\u001b[39m     fn_idx = np.where((targs[:,cls_idx]==\u001b[32m1\u001b[39m) & (bin_preds[:,cls_idx]==\u001b[32m0\u001b[39m))[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'probs' is not defined"
     ]
    }
   ],
   "source": [
    "# === Failure-case gallery (save False Negatives) ===\n",
    "FAIL_DIR = os.path.join(OUT_DIR, 'failure_gallery'); os.makedirs(FAIL_DIR, exist_ok=True)\n",
    "bin_preds = (probs >= best_thr.reshape(1,-1)).astype(int)\n",
    "for cls_idx, cls_name in enumerate(label_cols):\n",
    "    fn_idx = np.where((targs[:,cls_idx]==1) & (bin_preds[:,cls_idx]==0))[0]\n",
    "    for i, ix in enumerate(fn_idx[:6]):\n",
    "        img_name = names[ix]\n",
    "        try:\n",
    "            p = None\n",
    "            for ext in ['.jpg','.jpeg','.png','.tif','.tiff','']:\n",
    "                cand = os.path.join(IMG_DIR, img_name + ext)\n",
    "                if os.path.exists(cand):\n",
    "                    p = cand; break\n",
    "            if p is None:\n",
    "                p = glob(os.path.join(IMG_DIR, img_name + '*'))[0]\n",
    "            im = Image.open(p).convert('RGB').resize((IMG_SIZE, IMG_SIZE))\n",
    "            im.save(os.path.join(FAIL_DIR, f\"FN_{cls_name}_{i}_{os.path.basename(p)}\"))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "print('Saved failure cases to', FAIL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f234d7",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "- Prediction report: /mnt/data/output/val_prediction_report_with_uncertainty.csv\n",
    "- Grad-CAM overlays: /mnt/data/output/gradcam_overlays\n",
    "- Failure cases: /mnt/data/output/failure_gallery\n",
    "\n",
    "Adjust batch size or IMG_DIR if needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
